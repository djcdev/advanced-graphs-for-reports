---
#authors: "Victor Espinosa, Alvaro Ciganda, Joel Cohen"
output: html_document

params:
  pid: 0
  reportId: 0
  server_url: ""
  token: ""
  dynamic_filter1: ""
  dynamic_filter2: ""
  dynamic_filter3: ""
  lf1: ""
  lf2: ""
  lf3: ""
---

# Test


```{r setup, include=FALSE }
#knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
knitr::opts_chunk$set(echo = FALSE)


# Used for connections
library(RCurl)

# --- Used for creating plots ---
# Used for many nice looking plots
library(ggplot2)

# Used for likert plots
library(likert)

# Used to get good color palettes
library(RColorBrewer)
getPalette = colorRampPalette(brewer.pal(8, "Set2"))
library(viridis)

# Used for tables
library(kableExtra)

# Necessary for all percents in likert plot
library(plyr, include.only = c("ddply", "."))

# Used to create maps
library(leaflet)

# Used to create network graphs
library(igraph)

# Used to extract trailing numbers from checkboxes
library(stringr)

# -------------------------------

# --- Used for data manipulation ---
library(dplyr)
library(tidyr)
options(dplyr.summarise.inform = FALSE)

# Used to create dataframe with category lists for likert
library(data.table, exclude = c("hour", "isoweek", "mday", "minute", "month", "quarter", "second", "wday", "week", "yday", "year"))
# ----------------------------------
```

```{r data_processing_functions, results='asis'}
# title_caps
# Author: Joel Cohen (Based on previously existing work)
# Description:
# 
# Takes a character array or vector of character arrays of and transforms 
# capitalizes the first letter of each word.
# 
# e.g.
# Input:
#
# c("lorem ipsum dolor sit amet", "the quick brown dog jumped") 
#
# Returns:
#
# c("Lorem Ipsum Dolor Sit Amet", "The Quick Brown Dog Jumped")
title_caps <- function (string_vec) {
  string_vec <- if (typeof(string_vec) == "character") c(string_vec) else string_vec
  vapply(strsplit(string_vec, " "), FUN = function(x) {paste(toupper(substr(x, 1, 1)), substr(x, 2, nchar(x)), collapse = " ", sep = "")}, FUN.VALUE = "")
}

# import_data
# Author: Joel Cohen (Based on previously existing work)
# Description:
# 
# Retrieves a REDCap report's data frame with live filters applied
# If no parameters are supplied, it uses local files for the data frames.
#
# Input:
#   params:
#     pid: 0
#     reportId: 0
#     server_url: ""
#     token: ""
#     dynamic_filter1: ""
#     dynamic_filter2: ""
#     dynamic_filter3: ""
#     lf1: ""
#     lf2: ""
#     lf3: ""
#
#   live_filters:
#     field_name <chr>    option_code <chr>     option_name <chr> field_title <chr>
#     ...........................................................................
#     field1  	                  1	              option2	           Field 1
#     field2  	                  3	              option1  	         Field 2
#     instrument_one_complete     2	              Complete	       Instrument One
#     ...........................................................................
#
# Returns:
# 
# A dataframe containing the report fields with any applicable live filter.
#
# NOTE: entry ID MUST be a field in the report for this to work!
# TODO: Make local files non-static
import_data <- function(parameters, record_id, live_filters) {
  # TODO: We could filter locally if we didn't have to worry abour fields that aren't in the report
  ##########################
  # REDCap Report
  ##########################
    report_data <- read.csv(text = postForm(
        uri=parameters$server_url,
        token=parameters$token,
        content='report',
        format='csv',
        report_id=parameters$reportId,
        rawOrLabel='raw',
        rawOrLabelHeaders='raw',
        exportCheckboxLabel='false',
        returnFormat='csv',
       .opts = RCurl::curlOptions(ssl.verifypeer = FALSE, ssl.verifyhost = FALSE, verbose=FALSE)
      ), header = TRUE, sep = ",", stringsAsFactors = FALSE)
  
    
    # If there are no live_filters active, submit the report_data
    if (nrow(live_filters) == 0) return(report_data)
    
    # If live filters are selected but there are duplicate entries 
    # in the report column report data_frame, return null
    # live filter records must be merged on the entry ids
    if (anyDuplicated(report_data)) return(data.frame())
  
  # Create filter condition to send request to redcap.
  filter_condition <- paste("[", live_filters$field_name, "] = \"", live_filters$option_code, "\"" ,sep = "", collapse = " AND ")
  
  
  # Create the array of field names to be returned from redcap
  report_fields <- toString(names(report_data))
  
  # All records matching live filter
  live_filtered_records <- read.csv(text = postForm(
      uri=parameters$server_url,
      token=parameters$token,
      content='record',
      fields= report_fields,
      format='csv',
      filterLogic = filter_condition,
      rawOrLabel='raw',
      rawOrLabelHeaders='raw',
      exportCheckboxLabel='false',
      returnFormat='csv',
     .opts = RCurl::curlOptions(ssl.verifypeer = FALSE, ssl.verifyhost = FALSE, verbose=FALSE)
    ), header = TRUE, sep = ",", stringsAsFactors = FALSE)

  return(
    report_data %>%
      group_by_all() %>%
      mutate(adv_graph_internal_duplicates_id = row_number()) %>% 
      inner_join(live_filtered_records %>%
                 select(names(report_data)) %>%
                 group_by_all() %>%
                 mutate(adv_graph_internal_duplicates_id = row_number())    
                ) %>%
      select(-adv_graph_internal_duplicates_id)# TODO: Test this solutions
  )
}

# post_project_info
# Author: Joel Cohen
# Description:
# 
# Uses the relevant parameters to request a the project info from REDCap
# 
# Input: 
#   params:
#     pid: 0
#     reportId: 0
#     server_url: ""
#     token: ""
#     dynamic_filter1: ""
#     dynamic_filter2: ""
#     dynamic_filter3: ""
#     lf1: ""
#     lf2: ""
#     lf3: ""
#
# Returns:
#
#   REDCap project info
post_project_info <- function (parameters) {
  ##########################
  # Project Dataframe
  ##########################
  read.csv(text = postForm(
    uri= parameters$server_url,
    token= parameters$token,
    content='project',
    format='csv',
    returnFormat='csv',
    .opts = RCurl::curlOptions(ssl.verifypeer = FALSE, ssl.verifyhost = FALSE, verbose=FALSE)
  ), header = TRUE, sep = ",", stringsAsFactors = FALSE)
}

# post_data_dictionary
# Author: Joel Cohen
# Description:
# 
# Uses the relevant parameters to 
# 
# Input: 
#   params:
#     pid: 0
#     reportId: 0
#     server_url: ""
#     token: ""
#     dynamic_filter1: ""
#     dynamic_filter2: ""
#     dynamic_filter3: ""
#     lf1: ""
#     lf2: ""
#     lf3: ""
#
# Returns:
#
#   A REDCap data dictionary
post_data_dictionary <- function (parameters) {
  ##########################
  # Data Dictionary
  ##########################
  # Reads a very large string for all dd from REDCap
  read.csv(text = postForm(
    uri=parameters$server_url,
    token= parameters$token,
    content='metadata',
    format='csv',
    returnFormat='csv',
   .opts = RCurl::curlOptions(ssl.verifypeer = FALSE, ssl.verifyhost = FALSE, verbose=FALSE)
  ), header = TRUE, sep = ",", stringsAsFactors = FALSE)
}

# parse_categories
# Author: Joel Cohen
# Description:
# 
# Takes filtered fields from a REDCap Data Dictionary and extracts the options for each categorical variable.
# 
# Input:
#
#   required: A REDCap Data Dictionary containing relevant field names
# 
#
# Returns:
#
#   A Nested list of the form:
#
#   $field_name1
#     $field_name1$field_name
#     [1] "field_name1"
#
#     $field_name1$field_label
#     [1] "Field Name One"
#
#     $field_name1$options_code
#     [1] "1", "2", "3"
#
#     $field_name1$options_label
#     [1] "option 1", "option 2", "option 3"
#
#   $field_name2
##     $field_name2field_name
#     [1] "field_name2"
#
#     $field_name2$field_label
#     [1] "Field Name Two"
#     
#     $field_name2$options_code
#     [1] "A", "B", "C"
#
#     $field_name2$options_label
#     [1] "option A", "option B", "option C"
parse_categories <- function(data) {
  # Create a list of categories
  mapply(
    function(field_name, field_label, options) {
    # For each category include
     list(
       # The field name
       field_name = field_name,
       # field label
        field_label = field_label,
       # option codes
        options_code = options[,1],
       # option labels
       # Name this by the options_code and fix duplicate names
        options_label = mapply(function(x,y) y, options[,1], vctrs::vec_as_names(options[,2], repair = "unique", quiet = TRUE))
     )
    },
    data$field_name, 
    data$field_label, 
    # split the categories into separate options
    str_split(data$select_choices_or_calculations, "[|]") %>%
    # then split each option into its code and label and remove whitespace
    lapply(function(x) gsub("^\\s+|\\s+^", "", str_split(x, pattern = ",", n=2, simplify = TRUE))),
    SIMPLIFY = FALSE
    )
}

# parse_live_filters
# Author: Joel Cohen
# Description:
# 
# Creates a dataframe of the filter field, field_tile, option_code and option_label given 
# A categories list and parameters
#
# Input: 
#   parameters  - params:
#                   pid: 0
#                   reportId: 0
#                   server_url: ""
#                   token: ""
#                   dynamic_filter1: ""
#                   dynamic_filter2: ""
#                   dynamic_filter3: ""
#                   lf1: ""
#                   lf2: ""
#                   lf3: ""
#
#   categories  - A nested list of categorical fields and their options.
#
#   live_filter_status (Optional) - A named list mapping instrument filter codes to 
#                                   Incomplete, Unverified and Complete
# 
# Returns:
#
# A dataframe of the form:
#
#
# field_name <chr>    option_code <chr>     option_name <chr> field_title <chr>
# ...........................................................................
# field1  	                  1	              option2	           Field 1	
# field2  	                  3	              option1  	         Field 2	
# instrument_one_complete     2	              Complete	       Instrument One
# ...........................................................................
parse_live_filters <- function (parameters, categories, data_dictionary,live_filter_status = c("0" = "Incomplete","1"="Unverified","2" = "Complete")) {
  data.frame(field_name = c(params$dynamic_filter1, params$dynamic_filter2, params$dynamic_filter3), option_code = c(params$lf1, params$lf2, params$lf3)) %>%
  # Remove empty filters
  filter(option_code != "") %>%
  mutate(
     # Match the option_name to match to option_code from the instrument or categories list
     option_name = if_else( # Match titles for filters
        # If the field name ends in _complete
        substr(field_name, nchar(field_name)-8, nchar(field_name)) == "_complete", 
        # Let the label equal the corresponding status
        live_filter_status[option_code],
        # Otherwise...
        if_else( 
          # ... If the options code is equal to [NULL]
          option_code == "[NULL]",
          # Change it to an empty string (this is for the filter condition to send to REDCap)
          "",
          # In all other cases
          unlist(mapply(     
            # Attempt to map the option_name to the corresponding field_name, option_code in the categories list
            function(filter_name, code, options) {
              # If the code is in the corresponding field_name's options
              if (code %in% options[[filter_name]][["code"]]) 
                # Use the options label corresponding to that code
                options[[filter_name]][["label"]][which(code == options[[filter_name]][["code"]])] 
                # Otherwise, let it be empty
              else NA
            },
                field_name, option_code, MoreArgs = list(options = categories)
          ))
        )
     ),
    # Add a pretty field title
    field_title = if_else(
      # If the field_name ends in _complete
      substr(field_name, nchar(field_name)-8, nchar(field_name)) == "_complete",
      # Remove _complete, split it over underscores, and capitalize the first letter of each word\
      # e.g. Example_instrument_complete => Example Instrument
      gsub("_", " ", substr(field_name, 0, nchar(field_name)-9)) %>% title_caps(),
       # Otherwise try to match it with field label from the data_dictionary
      right_join(data_dictionary, data.frame(field_name = field_name), by = "field_name")[["field_label"]]
    )
  )
} 
```

```{r custom_plots}
# custom_likert
# Author: Joel Cohen
# Description:
#   
#   Takes a dataframe containing factors and returns a likert plot
#
#   Input:
#     
#     A dataframe containing factors with the same levels
#
#   Output:
#     
#     A likert plot
custom_likert <- function(x) {
  likert.bar.plot(likert(x),
            as.percent = TRUE,
            low.color="forestgreen",
            high.color = "red3",
            neutral.color = "lightgoldenrod",
            horizontal=TRUE,
            plot.percents = TRUE,
            xscale.components=xscale.components.top.HH,
            yscale.components=yscale.components.right.HH,
            xlimEqualLeftRight=FALSE,
            xTickLabelsPositive=TRUE,
            reverse=FALSE,
            xlab = "Percent",
            ylab.right = "")
}

# custom_scatter
# Author: Joel Cohen
# Description:
#   
#   Takes a dataframe containing two numerical columns and field labels and returns a scatterplot
#
#   Input:
#     
#     A dataframe containing two numerical columns and a list of field labels
#
#   Output:
#     
#     A scatter plot
custom_scatter <- function(data, field_labels = NULL, date_fields = c()) {
  # If any number of columns other than two is provided, stop
  if (ncol(data) != 2) stop(paste0("custom_scatter takes a dataframe with two columns, (",ncol(data),") provided."))
  
  # If field_labels is NULL use the names of the passed dataframes
  if (is.null(field_labels)) {
    field_labels <- names(data)
  } else if (length(field_labels) != 2 || typeof(field_labels) != "character") {
    stop("field_labels must be a character vector or character list of length 2")
  }
  
  data %>%
    mutate(across(all_of(date_fields), as.Date, tryFormats = c("%m/%d/%Y", "%Y-%m-%d", "%Y/%m/%d"))) %>%
    na.omit() %>%
    (function(fixed_data) {
      if (nrow(fixed_data) != 0) {
        plot(
          fixed_data,
          main = paste0(field_labels, collapse = " vs "),
          xlab = field_labels[1],
          ylab = field_labels[2],
          type = "p",
          xaxt = "n",
          yaxt = "n",
          # TODO: Make point sizes increase for repeated (y?) values
          #cex= points_to_plot[,3]
          pch=19, 
          col="blue"
        )
        if (length(date_fields) == 0) {
          axis(side = 1, labels = TRUE, las = 1)
          axis(side = 2, labels = TRUE, las = 1)
        } else if (length(date_fields) == 1) {
          axis.Date(side = which(names(fixed_data) == date_fields), fixed_data[[date_fields]], labels = TRUE, las = 1)
          axis(side = which(names(fixed_data) != date_fields), labels = TRUE, las = 1)
        } else {
          axis.Date(side = 1, fixed_data[[date_fields[1]]], labels = TRUE, las = 1)
          axis.Date(side = 2, fixed_data[[date_fields[2]]], labels = TRUE, las = 1)
        }
      }
    })
}

# # custom_scatter_date
# # Author: Joel Cohen
# # Description:
# #   
# #   Takes a dataframe containing a date column as x and a numerical column as y and field labels and returns a scatterplot
# #
# #   Input:
# #     
# #     A dataframe containing a date column as the first field, a numerical column as the second field and a (optional) list of field labels
# #
# #   Output:
# #     
# #     A date scatter plot
# custom_scatter_date <- function(data, field_labels = NULL) {
#   # If any number of columns other than two is provided, stop
#   if (ncol(data) != 2) stop(paste0("custom_scatter_date takes a dataframe with two columns, (",ncol(data),") provided."))
#   
#   # If field_labels is NULL use the names of the passed dataframes
#   if (is.null(field_labels)) {
#     field_labels <- names(data)
#   } else if (length(field_labels) != 2 || typeof(field_labels) != "character") {
#     stop("field_labels must be a character vector or character list of length 2")
#   }
#   
#   data %>%
#     na.omit() %>%
#     (function(data) {
#       if (nrow(data) != 0) {
#         plot(
#           data,
#           main = paste0(field_labels, collapse = " vs "),
#           xlab = field_labels[1],
#           ylab = field_labels[2],
#           type = "p",
#           xaxt = "n",
#           yaxt = "n",
#           # TODO: Make point sizes increase for repeated (y?) values
#           #cex= points_to_plot[,3]
#           pch=19, 
#           col="blue"
#         )
#       }
#     })
# }

# custom_bars
# Author: Joel Cohen
# Description:
#   
#   Takes a dataframe containing one factor column and one numerical column and creates a  barplot
#
#   Input:
#     
#     A dataframe containing one factor column as x and one numeric column as y
#
#   Output:
#     
#     A bar plot
custom_bars <- function(data, x, y, label2 = NULL, percent = FALSE, margin = 15, angle_rotation = 45, v_just = 0.5, x_title_size = 8, legend_size = 7) {
  # enquo the passed parameters to be used in aes
  x <- enquo(x)
  y <- enquo(y)
  label2 <- enquo(label2)
  
  # Get the number of rows in the data
  n_bars <- nrow(data)
  
  # Set the size of the label text based on the number of bars
  label_size <- if (n_bars > 7) 3 else 5
  
  # If there are more than 25 bars rotate the labels 90 degrees
  if (n_bars > 25) {
    angle_rotation <- 90
    v_just <- 0
  }
  
  # If label2 isn't passed or there are more than 25 bars
  if (rlang::quo_is_null(label2))
    # If percent is TRUE plot the labels as percents
    if (percent)
      bar_labels <- geom_text(aes(label = scales::percent(!!y)), vjust = -0.5, size = label_size)
    # If percent is FALSE plot the labels as is
    else
      bar_labels <- geom_text(aes(label = !!y), vjust = -0.5, size = label_size)
  # If label2 is passed and there are fewer than 26 bars
  else if (n_bars < 26)
    # If percent is TRUE
    if (percent)
      # Print the y labels as is and plot the second labels as percent
      bar_labels <- geom_text(aes(label=paste0(!!y ," (",scales::percent(!!label2),")")), vjust = -0.5, size = label_size)
    else
      # If percent is FALSE plot both y and the second labels as is
      bar_labels <- geom_text(aes(label = paste0(!!y ," (",!!label2,")")), vjust = -0.5, size = label_size)
  # If label2 is passed but there are more than 25 bars
  else 
    # Print the labels as if percent wasn't passed
    bar_labels <- geom_text(aes(label = !!y), vjust = -0.5, size = label_size)
  
  # Pass the data to ggplot
  data %>%
  # Use x and y as out x and y
  ggplot(aes(x=!!x, y = !!y)) +
      # Create bars
      geom_bar(stat = "identity", color="black", fill= getPalette(n_bars)) +
            # Add a border
      theme(panel.border = element_rect(linetype = "blank", size= 0.9, fill = NA),
            # Adjust the position of the title
            plot.title = element_text(hjust = 0.5),
            # Set the margins to the margins parameter (default 15)
            plot.margin = margin(margin,margin,margin,margin),
            #axis.title.x = element_text(size=x_title_size),
            axis.text.x = element_text(#size=label_size,
              # Set the angle of the category labels based on bar count
              angle = angle_rotation,
              vjust = v_just,
              # Set the colour of the text to black
              colour = "black"
            ),
            # Set the parameters for the y title
            axis.title.y = element_text(
              size=10,
              colour = "black"
            ),
            # Add a legend ant set its position
            legend.position = "bottom",
            legend.box = "horizontal"
            )  +
            # Increase the top of the y-axis so labels don't spill off the plot
            scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +
            # Add the previously created x axis labels
            bar_labels
}

# custom_stacked
# Author: Joel Cohen
# Description:
#   
#   Takes a dataframe with three columns and produces a stacked bar plot
#
#   Input:
#     
#     data - a dataframe with two categorical columns and one numeric
#
#     x - the categories which will be bars along the x axis
#
#     y - the categories which will be stacked on top of the bars
#
#     fill - the values used to determine the height of each piece of the stack
#
#   Output:
#     
#     A stacked bar plot
custom_stacked <- function(data, x, y, fill, title = "") {
  # Enquo our passed parameters so they can be used in aes
  x <- enquo(x)
  y <- enquo(y)
  fill <- enquo(fill)
  
  # Count the number of bars
  n_bars = data %>% select(!!x) %>% distinct() %>% nrow()
  
  # Count the number of stacks
  n_stacks = data %>% select(!!y) %>% distinct() %>% nrow()
  
  # Set parameters for when there 34 or fewer bars or stacks
  angle_rotation = 45
  v_just = 0.5
  x_size = 8
  legend_size = 7
  
  # If there are more than 34 bars
  if (n_bars > 34) {
    # Rotate the x labels to 90 degrees
    angle_rotation = 90
    v_just = 0
  }
  
  # If there are more than 34 stacks
  if (n_stacks > 34) {
    # Decrease the size of the label text
    x_size = 7
    # And decrease the legend size
    legend_size = 5
  }
  
  # Pass the data to ggplot
  data %>%
    # Use the passed parameters
    # TODO: Swap fill and y?
    ggplot(aes(x=!!x, fill = !!y, y = !!fill)) +
    # Add bars
    geom_bar(position = "stack", color="darkblue", stat = "identity") +
    # Use a viridis colour scaling
    scale_fill_viridis(discrete = T, option = "H") +
    # Add a title to the plot
    ggtitle(title) +
    # Remove the title from the guide
    guides(fill=guide_legend(title='')) +
    theme(
      # Add a border
      panel.border = element_rect(linetype = "blank", size= 0.9, fill = NA),
      # Adjust the location of the title
      plot.title = element_text(hjust = 0.5),
      # Specify the margin
      plot.margin = margin(0.15,0.15,0.15,0.15),
      # Set the size of the x title
      axis.title.x = element_text(size=x_size),
      # Set the size, rotation and position of the x labels
      axis.text.x = element_text(size=x_size,
                                 angle = angle_rotation,
                                 vjust = v_just),
      # Set the size of the y title
      axis.title.y = element_text(size=10),
      # Add a legend
      legend.text = element_text(size=legend_size),
      # Position the legend at the bottom
      legend.position = "bottom",
      # Set the legend to display horizontally
      legend.box = "horizontal"
    )
}

# custom_crosstab
# Author: Joel Cohen
# Description:
#   
#   Takes a dataframe in the style of a contingency table and a label for the 
#   columns and produces a kable table of that style.
#
#   Input:
#     
#     A dataframe in the style of a contingency table and a label for the 
#     columns.
#
#   Output:
#     
#     A contingency table
custom_crosstab <- function(data, column_spanner = "Columns") {
  spanner <- c(1, ncol(data)-1)
  names(spanner) <- c(" ", column_spanner)
  
  data %>%
    kable() %>%
    add_header_above(spanner)
}

custom_map <- function(data, title = "") {
  data %>%
    leaflet() %>%
    addTiles() %>%
    addCircleMarkers(
      radius =3,
      opacity = 1,
      fillOpacity = 1,
      fill = TRUE,
      fillColor = "#FF0000",
      clusterOptions = markerClusterOptions( spiderfyOnMaxZoom = TRUE, spiderLegPolylineOptions = list(weight = 1.5, color = "#FF0000", opacity = 1))
    ) %>%
    addControl(title, position = "bottomleft")
}
```


```{r data_input}
# TODO: The if statement is temporary and allows for testing on sample data
if (params$pid != 0) {
  # Get report metadata
  project_info <- post_project_info(params)
  data_dictionary <- post_data_dictionary(params)
  
  # Get a list of categories and their options
  categories <- parse_categories(data_dictionary)
  
  # Retrieve the live filters
  live_filters <- parse_live_filters(params, categories, data_dictionary)
  
  # Retrieve report data
  report_data <- import_data(params, data_dictionary$field_name[1], live_filters)
} else {
  # Data dictionary is same one from Advanced Graphs - Demo Project
  data_dictionary <- read.csv(file = "./sample/sample_data_dictionary.csv", header = TRUE)
  categories <- parse_categories(data_dictionary)
  
  project_info <- data.frame(project_title = c("Sample Data"))
  
  live_filters <- data.frame(c())
  
  # Report data was randomly sampled from Advanced Graphs - Demo Project
  report_data <- read.csv(file = "./sample/sample_report_data.csv", header = TRUE)
}
# Create list of labels
names_to_labels <- data_dictionary$field_label
names(names_to_labels) <- data_dictionary$field_name
```

## Advanced Graphs 

### `r project_info$project_title`
#### project pid `r params$pid`
#### Number of results returned: `r nrow(report_data)`
##### Live filter(s)
###### `r if (nrow(live_filters) > 0) paste0(live_filters$field_title, " = ", live_filters$option_name, collapse = "\n")`
<!--TODO: fix '=' when no live filters selected -->
```{r}
# TODO: Delete
# print(project_info)
#print(data_dictionary)
# print(categories)
# print(live_filters)
# print(report_data)
```


```{r likert_plots}
# Likert types
like_likert <- c("dropdown", "radio")
key_likert_words <- c("not useful", "not at all useful", "difficult", "none of my needs", "strongly disagree", "somewhat disagree", "completely disagree", "quite dissatisfied", "very dissatisfied", "Extremely dissatisfied", "poor", "never", "worse", "severely ill", "inutil", "in\u00fatil", "completamente inutil", "completamente in\u00fatil", "dificil", "dif\u00edcil", "ninguna de mis necesidades", "totalmente en desacuerdo", "parcialemnte en desacuerdo", "completamente en desacuerdo", "muy insatisfecho(a)", "totalmente insatisfecho(a)", "nunca", "peor", "gravemente enfermo")

# From the data dictionary
likert_groups <- data_dictionary %>%
  filter(
    # Select only the fields that are in the report
    field_name %in% names(report_data) 
    # That have a field type that can be likert
    & field_type %in% like_likert
    # And whose options contain a likert keyword
    & grepl(paste0("*",tolower(key_likert_words), "*", collapse = "|"), tolower(select_choices_or_calculations))
  ) %>%
  # Group the fields that have the same options
  group_by(select_choices_or_calculations) %>%
  # Take a list of field names and labels
  summarise(field_name = list(field_name), field_label = list(field_label)) %>%
  # Parse the categories into a useful format
  parse_categories()

# For each set of fields that share options
for (likert_group in likert_groups) {
    report_data %>%
      # Select these fields from the data dictionary and turn them into factors
      transmute(across(all_of(likert_group$field_name), factor, levels = likert_group$options_code, labels = likert_group$options_label, .names = "{likert_group$field_label}")) %>%
      (function(data) {
        # If any of the fields contain an NA
       if (any(is.na(data))) { 
         return(
           # Add an NA field to each factor
           transmute(data, across(.fns = addNA)) 
         )
       } 
        # Otherwise return the data as is
        return(data) 
      }) %>%
      # Pass this dataframe to the custom likert
      custom_likert() %>%
      # print this plot
      print()
}
```

```{r scatter_plots}
# Fields to ignore if any of these words appear anywhere in the field name
ignored_names = c("latitude", "longitude", "latitud", "longitud")

accepted_text_validation = c("integer", "number", "float", "decimal")

# Get numerical fields
numerical_data_fields <- data_dictionary %>%
  filter(
    # The field name is in the report
    field_name %in% names(report_data)
    # The field type isn't null
    & !is.na(field_type) 
    # If the field type is text but there is no text validation, don't include (text field)
    & !(field_type == "text" & is.na(text_validation_type_or_show_slider_number)) 
    # Include only fields where either:
    & (
      # The field type is calc
      field_type == "calc" 
      # If the field type is text it uses a recognized validation format
      | (field_type == "text" 
          & grepl(paste0("*",accepted_text_validation, "*", collapse = "|"), text_validation_type_or_show_slider_number))
      )
      # And is not one of the ignored_names
    & !grepl(paste0("*", ignored_names, "*", collapse = "|"), field_name)
  ) %>%
  select(field_name) %>%
  unlist()

for (x_field in numerical_data_fields) {
  # And each field considered y
  for (y_field in numerical_data_fields) {
    # Excluding field_x = field_y
    if (y_field != x_field)
      custom_scatter(report_data[, c(x_field, y_field)], names_to_labels[c(x_field, y_field)])
  } 
}

# Get date fields
date_data_fields <- data_dictionary %>%
  # Select only fields in the report
  filter(field_name %in% names(report_data)
         # Select only fields that start with 'date'
         & substr(text_validation_type_or_show_slider_number, 1, 4) == "date") %>%
  # Select the field name
  select(field_name) %>%
  # Return field names in vector
  unlist()

# For each date_field (x in date - date plots)
for (date_field_x in date_data_fields) {
  # And numeric_field
  for (numeric_field in numerical_data_fields) {
      # Plot date as x and numeric as y
      custom_scatter(report_data[,c(date_field_x, numeric_field)], names_to_labels[c(date_field_x, numeric_field)], date_fields = date_field_x)
      # Plot numeric as x and date as y
      custom_scatter(report_data[,c(numeric_field, date_field_x)], names_to_labels[c(numeric_field, date_field_x)], date_fields = date_field_x)
  }
  
  # For each date_field
  for (date_field_y in date_data_fields) {
    # If the x date field and y date field are different
    if (date_field_x != date_field_y){
      # Create a custom scatter plot with the two date fields
      custom_scatter(report_data[,c(date_field_x, date_field_y)], names_to_labels[c(date_field_x, date_field_y)], date_fields = c(date_field_x, date_field_y))
    }
  }
}

```

```{r bar_plots}
# Get a parsed list of each checkbox field
checkbox_fields <- data_dictionary %>%
  filter(field_type == "checkbox") %>%
  parse_categories()

for (checkbox_field in checkbox_fields) {
  # If there is at least on field of the form "field_name___[0-9]+" in the report_data
  # create a plot
  if (any(grepl(paste0(checkbox_field$field_name, "___[0-9]+\\b"), names(report_data)))) {
    checkbox_plot <- report_data %>%
      # Select each column of the report data that matches the current checkbox field
      select(matches(paste0(checkbox_field$field_name, "___[0-9]+\\b"))) %>%
      # Let each column be it's own level in a factor column
      pivot_longer(cols = everything())  %>%
      # remove NA entries
      na.omit() %>%
      group_by(name, .drop = FALSE) %>%
      # Get the count and proportion for each of the checkboxes
      summarise(count = sum(value), percent = count/n())  %>%
      # Use the field label as the name 
      transmute(
        # Use the field_label as the name for the options
        "{checkbox_field$field_label}" := 
          # replace the field_name__1 with the corresponding label
          factor(checkbox_field$options_label[str_extract(name, "[0-9]+\\b")], levels = checkbox_field$options_label), 
        # Include counts and percents
        count, 
        percent) %>%
      # Create a custom bar plot
      custom_bars(x = !!sym(checkbox_field$field_label), y = count, label2 = percent, percent = TRUE) %>% print()
  }
}

# Radio or dropdown fields
radio_categories <- data_dictionary %>%
  # Select fields from the data dictionary
  filter(
    # Where they are of "radio" type
    field_type %in% c("radio", "dropdown", "yesno", "truefalse")
    # The field name is in the report data
    & field_name %in% names(report_data)
    # And there are options
    & select_choices_or_calculations != "") %>%
  # Turn them into a list of category attributes
  parse_categories()

for (radio_category in radio_categories) {
  # If the entire column isn't NA
  if (!all(is.na(report_data[[radio_category$field_name]])))
  report_data %>%
    transmute(
      # Select the column
      across(all_of(radio_category$field_name), 
             # Turn it into a factor
             function(column) {
               # add an NA level if there are NA's in the column
               addNA(factor(as.character(column), 
                            levels = radio_category$options_code, 
                            labels = radio_category$options_label), ifany=TRUE)
             },
             # Rename it the field label
             .names = radio_category$field_label)
      ) %>%
    # Get a count of each category
    group_by_all(.drop = FALSE) %>%
    summarise(count = n()) %>%
    mutate(percent = count/sum(count)) %>%
    # Create a custom bar plot
    custom_bars(x = !!sym(radio_category$field_label), y = count, label2 = percent, percent = TRUE) %>%
    # Print it
    print()
}

```

```{r numerical_bar_plots}
# For each radio category
for (category in radio_categories) {
  # If the category column isn't empty
  if (!all(is.na(report_data[[category$field_name]])))
  # For each numeric field
  for (numeric_field in numerical_data_fields) {
    # If the numeric column isn't empty
    if (!all(is.na(report_data[[numeric_field]])))
    report_data %>%
      transmute(
        # Turn radio category into factor
        across(all_of(category$field_name),
               function(column) {
                # add NA level if there are NAs present
                addNA(factor(column, 
                             levels = category$options_code, 
                             labels =  category$options_label), ifany = TRUE) 
               }, .names = "category"),
        # Select the numeric column
        across(all_of(numeric_field), .names = "numeric")
      ) %>% 
      # Remove entries where the numeric column is NA
      filter(!is.na(numeric)) %>% #print()
      # Group by the category and do not drop categories that do no show up in the data
      # TODO: Is this the behavior we want
      group_by(category, .drop = FALSE) %>%
      # Get the mean for each group, 0 if there are no numeric fields
      summarise(count = n(), mean = round(sum(numeric)/(if (count > 0) count else 1), 1)) %>%
      # Rename the columns by their respective field labels
      transmute("{category$field_label}" := category, "{paste0(names_to_labels[numeric_field], \" (mean)\")}" := mean) %>%
      # Create a custom bar plot
      custom_bars(x = !!sym(category$field_label), y = !!sym(paste0(names_to_labels[numeric_field], " (mean)"))) %>%
      # Print it
      print()
  }
}
```

```{r stacked_bars, results='asis'}
# For each pair of categories
for (category_x in radio_categories) {
  for (category_y in radio_categories) {
    # If the categories aren't the same
    if (category_x$field_name != category_y$field_name)
    report_data %>%
      transmute(
        # Turn both factors into columns
        across(c(category_x$field_name), 
                 function(column) {
                   # Adding NA as a factor if there are any NAs
                   addNA(factor(column,
                                # Using the option codes as the levels
                                levels = category_x$options_code, 
                                # Matching them to the labels and repairing empty or duplicate names
                                labels = category_x$options_label), ifany = TRUE)
                 },
               .names = "x_col"
        ),
        # Repeat for second column
        across(c(category_y$field_name), 
                 function(column) {
                   addNA(factor(column, 
                                levels = category_y$options_code, 
                                labels = category_y$options_label), 
                         ifany = TRUE)
                 },
               .names = "y_col"
        )
      ) %>%
      # Group by both columns and do not drop levels where there are no matches
      group_by(x_col, y_col, .drop = FALSE) %>%
      # Get a count of each pair of levels
      summarise(count = n()) %>%
      # Ungroup the data to avoid warning from transmute
      ungroup() %>%
      # Rename the columns to match the field labels
      transmute("{category_x$field_label}" := x_col,
                "{category_y$field_label}" := y_col,
                count) %>%
      (function(data) {
      data %>%
      # Create a custom stacked bar plot with the data
        custom_stacked(x = !!sym(category_x$field_label), y = !!sym(category_y$field_label), fill = count, title = paste0(category_x$field_label, " and ", category_y$field_label)) %>%
        print()
      

      # data %>%
      #   # Create a contingency table from the data
      #   pivot_wider(names_from = all_of(category_y$field_label), values_from = count, names_repair = "unique") %>%
      #   # Pass it to the custom crosstab function
      #   custom_crosstab(column_spanner = category_y$field_label) %>%
      #   # Print the custom crosstab
      #   print()
      })
  }
}
```


```{r maps, message=FALSE, out.width = "100%", fig.align="center", fig.height=8, fig.width=10}
longitude_keywords <- c("longitude", "longitud")
latitude_keywords <- c("latitude", "latitud")

longitudes <- data_dictionary %>%
  filter(grepl(paste0("*", longitude_keywords,"*", collapse = "|"), field_name)) %>%
  transmute(field_name, field_label, stripped_name = sapply(regmatches(field_name, gregexpr(pattern = paste0(longitude_keywords, collapse = "|"), field_name), invert = TRUE), paste0, collapse = "", USE.NAMES = FALSE))

latitudes <- data_dictionary %>%
  filter(grepl(paste0("*", latitude_keywords,"*", collapse = "|"), field_name)) %>%
  transmute(field_name, field_label, stripped_name = sapply(regmatches(field_name, gregexpr(pattern = paste0(latitude_keywords, collapse = "|"), field_name), invert = TRUE), paste0, collapse = "", USE.NAMES = FALSE))

coordinate_fields <- inner_join(longitudes, latitudes, by = "stripped_name") %>%
  {mapply(FUN = function(longitude_name, latitude_name, longitude_label, latitude_label) {
    list(
      longitude_name = longitude_name,
      latitude_name = latitude_name,
      longitude_label = longitude_label,
      latitude_label =latitude_label
    )
  }, longitude_name = .[,"field_name.x"], latitude_name = .[,"field_name.y"], longitude_label = .[,"field_label.x"], latitude_label = .[,"field_label.y"], SIMPLIFY = FALSE)}

maps <- lapply(coordinate_fields,
              function(coordinate_field) {
                report_data %>%
                  transmute(
                    across(all_of(coordinate_field$longitude_name), .names = "longitude"),
                    across(all_of(coordinate_field$latitude_name), .names = "latitude")
                  ) %>%
                  na.omit() %>%
                  group_by_all() %>%
                  summarise(count = n()) %>%
                  custom_map(title = paste0(coordinate_field$longitude_label, " vs ", coordinate_field$latitude_label))
              }
)

htmltools::tagList(maps)
```

```{r network_graphs}
text_fields <- data_dictionary %>%
  filter(field_type == "text") %>%
  {mapply(
    FUN = function(field_name, field_label) {
      list(
        field_name = field_name,
        field_label = field_label
      )
    }, .[["field_name"]], .[["field_label"]],
    SIMPLIFY = FALSE
  )}
text_fields <- text_fields[1:20]

for (text_pair in combn(text_fields, 2, simplify = FALSE)) {
  if(!all(is.na(report_data[[text_pair[[1]]$field_name]]))
     && !all(is.na(report_data[[text_pair[[2]]$field_name]])))
    report_data %>%
            transmute(across(all_of(c(text_pair[[1]]$field_name, text_pair[[2]]$field_name)),
                      function(column) {
                        addNA(factor(column), ifany = TRUE)
                      }
                        , .names = "{names_to_labels[.col]}")
            ) %>%
            graph_from_data_frame(directed = TRUE) %>%
            plot(edge.width = 2,
           main = paste0(text_pair[[1]]$field_label, " vs. " ,text_pair[[2]]$field_label),
           cex.main = 100,
           sub = "",
           edge.arrow.width = 0.3,
           vertex.size = 3,
           edge.arrow.size = 0.5,
           vertex.size2 = 3,
           vertex.label.cex = .75,
           asp = .65,
           margin = -0.1)
}
```



